






























































FHSI-GNN: Fusion Hierarchical Structure Information Graph Neural Network for Extractive Long Documents Summarization | SpringerLink






























Your privacy, your choice



We use essential cookies to make sure the site can function. We also use optional cookies for advertising, personalisation of content, usage analysis, and social media.By accepting optional cookies, you consent to the processing of your personal data - including transfers to third parties. Some third parties are outside of the European Economic Area, with varying standards of data protection.See our href0 for more information on the use of your personal data.Manage preferences for further information and to change your choices.



Accept all cookies










href1



Advertisement







href2

href3




href4


href5
href6
href7



href8


href9






Search



Search by keyword or author






Search






Navigation


href10


href11


href12












href13





href14





Conference paper



FHSI-GNN: Fusion Hierarchical Structure Information Graph Neural Network for Extractive Long Documents Summarization

Conference paper
First Online: 26 November 2023



 pp 136–149


href15






href16
(ICONIP 2023) 











href17href18, href19href20, href21href22, href23href24, href25href26, href27href28 & …href29href30,href31 Show authors







Part of the book series:
href32 ((CCIS,volume 1963))
                    








Included in the following conference series:

href33









565 Accesses








 AbstractExtractive text summarization aims to select salient sentences from documents. However, most existing extractive methods struggle to capture inter-sentence relations in long documents. In addition, the hierarchical structure information of the document is ignored. For example, some scientific documents have fixed chapters, and sentences in the same chapter have the same theme. To solve these problems, this paper proposes a Fusion Hierarchical Structure Information Graph Neural Network for Extractive Long Documents Summarization. The model constructs a section node containing sentence nodes and global information according to the document structure. It integrates the hierarchical structure information of the text and uses position information to identify sentences. The section node acts as an intermediary node for information interaction between sentences, which better enriches the relationships between sentences and has higher computational efficiency. Our model has achieved excellent results on two datasets, PubMed and arXiv. Further analysis shows that the hierarchical structure information of documents helps the model select salient content better.





                                
                                    This is a preview of subscription content, href34


 to check access.
                            


Access this chapter

href35





Subscribe and save





Springer+ Basic


      €32.70 /Month
     


Get 10 units per month
Download Article/Chapter or eBook
1 Unit = 1 Article or 1 Chapter
Cancel anytime
href36

Buy Now







 Chapter
      


        EUR 29.95
       


       Price includes VAT (Korea(Rep.))
      

        

Available as PDF
Read on any device
Instant download
Own it forever
Buy Chapter 
       







 eBook
      

       EUR 74.89
      

       Price includes VAT (Korea(Rep.))
      

    

Available as EPUB and PDF
Read on any device
Instant download
Own it forever
Buy eBook 
       







 Softcover Book
      

       EUR 89.99
      

       Price excludes VAT (Korea(Rep.))
      

    

Compact, lightweight edition
Dispatched in 3 to 5 business days
Free shipping worldwide - href37
Buy Softcover Book 
       






Tax calculation will be finalised at checkout
Purchases are for personal use only








href38





Similar content being viewed by others






href39


Chapter
© 2018









href40


Article
02 January 2020









href41


Article
Open access
02 May 2024







 ReferencesBeltagy, I., Peters, M.E., Cohan, A.: Longformer: the long-document transformer. arXiv preprint href42 (2020)Cho, S., Song, K., Wang, X., Liu, F., Yu, D.: Toward unifying text segmentation and long document summarization. In: Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, pp. 106–118 (Dec 2022)href43 
                Cohan, A., Dernoncourt, F., Kim, D.S., Bui, T., Kim, S., Chang, W., Goharian, N.: A discourse-aware attention model for abstractive summarization of long documents. arXiv preprint href44 (2018)Cui, P., Hu, L.: Sliding selector network with dynamic memory for extractive summarization of long documents. In: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pp. 5881–5891 (2021)href45 
                Cui, P., Hu, L., Liu, Y.: Enhancing extractive text summarization with topic-aware graph neural networks. arXiv preprint href46 (2020)Doan, X.D., Le Nguyen, M., Bui, K.H.N.: Multi graph neural network for extractive long document summarization. In: Proceedings of the 29th International Conference on Computational Linguistics, pp. 5870–5875 (2022)href47 
                Dong, Y., Mircea, A., Cheung, J.C.: Discourse-aware unsupervised summarization of long scientific documents. arXiv preprint href48 (2020)Dong, Z., Tang, T., Li, L., Zhao, W.X.: A survey on long text modeling with transformers. arXiv preprint href49 (2023)Erkan, G., Radev, D.R.: Lexrank: graph-based lexical centrality as salience in text summarization. J. Artif. Intell. Res. 22, 457–479 (2004)href50 
    href51 
                Grail, Q., Perez, J., Gaussier, E.: Globalizing bert-based transformer architectures for long document summarization. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 1792–1810 (2021)href52 
                Huang, Y.J., Kurohashi, S.: Extractive summarization considering discourse and coreference relations based on heterogeneous graph. In: Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 3046–3052 (2021)href53 
                Iandola, F.N., Shaw, A.E., Krishna, R., Keutzer, K.W.: Squeezebert: what can computer vision teach NLP about efficient neural networks? arXiv preprint href54 (2020)Jing, B., You, Z., Yang, T., Fan, W., Tong, H.: Multiplex graph neural network for extractive text summarization. arXiv preprint href55 (2021)Liu, Y., Lapata, M.: Text summarization with pretrained encoders. arXiv preprint href56 (2019)Miculicich, L., Han, B.: Document summarization with text segmentation. arXiv preprint href57 (2023)Phan, T.A., Nguyen, N.D.N., Bui, K.H.N.: Hetergraphlongsum: heterogeneous graph neural network with passage aggregation for extractive long document summarization. In: Proceedings of the 29th International Conference on Computational Linguistics, pp. 6248–6258 (2022)href58 
                Rohde, T., Wu, X., Liu, Y.: Hierarchical learning for generation with long source sequences. arXiv preprint href59 (2021)Ruan, Q., Ostendorff, M., Rehm, G.: HiStruct+: improving extractive text summarization with hierarchical structure information. In: Findings of the Association for Computational Linguistics: ACL 2022, pp. 1292–1308 (May 2022)href60 
                See, A., Liu, P.J., Manning, C.D.: Get to the point: summarization with pointer-generator networks. arXiv preprint href61 (2017)Sefid, A., Giles, C.L.: Scibertsum: extractive summarization for scientific documents. In: Document Analysis Systems: 15th IAPR International Workshop, DAS 2022, La Rochelle, 22–25 May 2022, Proceedings, pp. 688–701 (2022)href62 
                Steinberger, J., et al.: Using latent semantic analysis in text summarization and summary evaluation. Proc. ISIM 4(93–100), 8 (2004)href63 
                Vanderwende, L., Suzuki, H., Brockett, C., Nenkova, A.: Beyond sumbasic: task-focused summarization with sentence simplification and lexical expansion. Inf. Process. Manag. 43(6), 1606–1618 (2007)href64 
    href65 
                Wang, D., Liu, P., Zheng, Y., Qiu, X., Huang, X.: Heterogeneous graph neural networks for extractive document summarization. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 6209–6219 (2020)href66 
                Xiao, W., Carenini, G.: Extractive summarization of long documents by combining global and local context. arXiv preprint href67 (2019)Xiao, W., Carenini, G.: Systematically exploring redundancy reduction in summarizing long documents. arXiv preprint href68 (2020)Xu, J., Gan, Z., Cheng, Y., Liu, J.: Discourse-aware neural extractive text summarization. arXiv preprint href69 (2019)Yadav, A.K., Singh, A., Dhiman, M., Kaundal, R., Verma, A., Yadav, D.: Extractive text summarization using deep learning approach. Int. J. Inf. Technol. 14(5), 2407–2415 (2022)href70 
                Zhong, M., Liu, P., Chen, Y., Wang, D., Qiu, X., Huang, X.: Extractive summarization as text matching. In: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, pp. 6197–6208 (2020)href71 
                href72 AcknowledgementsThis research was supported by “Pioneer” and “Leading Goose” R &D Program of Zhejiang (Grant No. 2023C03203, 2023C03180, 2022C03174). Author informationAuthors and AffiliationsSchool of Cyberspace Security, Hangzhou Dianzi University, Hangzhou, 310018, ChinaZhen Zhang, Wenhao Yun, Xiyuan Jia, Qiyun Lv, Hao Ni, Xin Wang & Guohua WuData Security Governance Zhejiang Engineering Research Center, Hangzhou Dianzi University, Hangzhou, 310018, ChinaGuohua WuAuthorsZhen Zhanghref73You can also search for this author in
                        href74 href75Wenhao Yunhref76You can also search for this author in
                        href77 href78Xiyuan Jiahref79You can also search for this author in
                        href80 href81Qiyun Lvhref82You can also search for this author in
                        href83 href84Hao Nihref85You can also search for this author in
                        href86 href87Xin Wanghref88You can also search for this author in
                        href89 href90Guohua Wuhref91You can also search for this author in
                        href92 href93Corresponding authorCorrespondence to
                href94. Editor informationEditors and AffiliationsSchool of Automation, Central South University, Changsha, ChinaBiao Luo Institute of Automation, Chinese Academy of Sciences, Beijing, ChinaLong Cheng Institute of Cyber-Systems and Control, Zhejiang University, Hangzhou, ChinaZheng-Guang Wu School of Automation, Guangdong University of Technology, Guangzhou, ChinaHongyi Li School of Electrical Engineering and Telecommunications, UNSW Sydney, Sydney, NSW, AustraliaChaojie Li  Rights and permissionshref95 Copyright information© 2024 The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. About this paperhref96Cite this paperZhang, Z. et al. (2024).  FHSI-GNN: Fusion Hierarchical Structure Information Graph Neural Network for Extractive Long Documents Summarization.

                     In: Luo, B., Cheng, L., Wu, ZG., Li, H., Li, C. (eds) Neural Information Processing. ICONIP 2023. Communications in Computer and Information Science, vol 1963. Springer, Singapore. https://doi.org/10.1007/978-981-99-8138-0_12Download citationhref97href98href99DOI: https://doi.org/10.1007/978-981-99-8138-0_12Published: 26 November 2023
                            Publisher Name: Springer, Singapore
                                Print ISBN: 978-981-99-8137-3
                                Online ISBN: 978-981-99-8138-0eBook Packages: href100href101Share this paperAnyone you share the following link with will be able to read this content:Get shareable linkSorry, a shareable link is not currently available for this article.Copy to clipboard
                                Provided by the Springer Nature SharedIt content-sharing initiative
                             Publish with ushref102










Access this chapter

href103





Subscribe and save





Springer+ Basic


      €32.70 /Month
     


Get 10 units per month
Download Article/Chapter or eBook
1 Unit = 1 Article or 1 Chapter
Cancel anytime
href104

Buy Now







 Chapter
      


        EUR 29.95
       


       Price includes VAT (Korea(Rep.))
      

        

Available as PDF
Read on any device
Instant download
Own it forever
Buy Chapter 
       







 eBook
      

       EUR 74.89
      

       Price includes VAT (Korea(Rep.))
      

    

Available as EPUB and PDF
Read on any device
Instant download
Own it forever
Buy eBook 
       







 Softcover Book
      

       EUR 89.99
      

       Price excludes VAT (Korea(Rep.))
      

    

Compact, lightweight edition
Dispatched in 3 to 5 business days
Free shipping worldwide - href105
Buy Softcover Book 
       






Tax calculation will be finalised at checkout
Purchases are for personal use only








href106
















Discover content

href107
href108



Publish with us

href109
href110
href111



Products and services

href112
href113
href114
href115



Our imprints

href116
href117
href118
href119
href120








Your privacy choices/Manage cookies


href121


href122


href123


href124


href125


href126





165.194.104.233

South Korea Trial Consortium (3001948335)  - Chung Ang University (3000120396)  - 7029 SpringerLink South Korea KESLI Korean Journal Package (3000256740)  - South Korea Trial Consortium (3000522537)  - 5539 SpringerLink South Korea KESLI Full OJA Consortium - (3000171421)  - 9823  SpringerLink South Korea Shinwon (3000699960)  - South Korea Full eJournal Con - Academic 2015-2017 (3991460179)  - 8064 South Korea KESLI Korean Consortium (3000251005)  - 5539 SpringerLink South Korea KESLI Full eJournal Consortium - Academic (3000175460) 

href127
© 2024 Springer Nature











